{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src = \"https://github.com/exponentialR/DL4CV/blob/main/media/BMC_Summer_Course_Deep_Learning_for_Computer_Vision.jpg?raw=true\" alt='BMC Summer Course' width='300'/>\n",
        "\n",
        "# BMC Summer Course: Deep Learning for Computer Vision\n",
        "## Walkthrough Excercise on YOLO for Object Detection\n",
        "\n",
        "Author: Samuel A.\n"
      ],
      "metadata": {
        "id": "OXWfo8iNpGzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "\n",
        "In this notebook, we will train a YOLOv5 model using the Ultralytics YOLO framework on a custom dataset.\n",
        "YOLO (You Only Look Once) is a state-of-the-art object detection algorithm known for its speed and accuracy.\n",
        "We will cover the following steps:\n",
        "\n",
        "1. Setting up the environment.\n",
        "2. Preparing the dataset.\n",
        "3. Configuring the dataset for YOLOv5.\n",
        "4. Training the YOLOv5 model on custom data.\n",
        "5. Evaluating the model's performance.\n",
        "6. Running inference on new images.\n",
        "7. Visualizing and saving results.\n",
        "\n"
      ],
      "metadata": {
        "id": "kUzZXnVLpQOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Setup the Environment\n",
        "\n",
        "\n",
        "We need to install the Ultralytics YOLOv5 framework and other necessary libraries.\n",
        "YOLOv5 is a powerful object detection model that is easy to use and customize.\n"
      ],
      "metadata": {
        "id": "_Llt7PSzpW6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the YOLOv5 package from Ultralytics\n",
        "!pip install ultralytics\n",
        "\n",
        "# Import required libraries\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnHjhfMnpbf3",
        "outputId": "bf154e27-2356-452d-9313-0e291b41dd36"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Using cached ultralytics-8.2.79-py3-none-any.whl.metadata (41 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Using cached ultralytics_thop-2.0.5-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.6.20)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Using cached ultralytics-8.2.79-py3-none-any.whl (869 kB)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached ultralytics_thop-2.0.5-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, ultralytics-thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 ultralytics-8.2.79 ultralytics-thop-2.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Prepare the Dataset\n",
        "\n",
        "For this project, we will use a custom dataset. YOLOv5 expects the dataset in a specific format:\n",
        "- Images should be placed in separate folders for training, validation, and testing.\n",
        "- Corresponding labels (bounding boxes and class labels) should be in `.txt` files with the same names as the images.\n",
        "\n",
        "The dataset directory structure should look like this:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "In each `.txt` label file, the annotations should be in the following format:\n",
        "<category> <x_center> <y_center> <width> <height>\n",
        "\n",
        "All values are normalized (between 0 and 1) relative to the image width and height.\n"
      ],
      "metadata": {
        "id": "7u6pa7zypq78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Configure the Dataset for YOLOv5\n",
        "\n",
        "Next, we need to create a YAML file that describes the dataset structure and classes.\n",
        "This file will be used by YOLOv5 during training and evaluation.\n",
        "\n",
        "Example data.yaml file:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n"
      ],
      "metadata": {
        "id": "bA51DJD_p6I0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this YAML file:\n",
        "- `train`, `val`, and `test` specify the paths to the corresponding image folders.\n",
        "- `nc` is the number of classes in the dataset.\n",
        "- `names` lists the names of the classes.\n",
        "\n",
        "Create this YAML file manually or programmatically.\n",
        "\n"
      ],
      "metadata": {
        "id": "GOxRu23EqNem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "L99u8WkIqaKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "import zipfile\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1w0xigcHNMuzeFcj0tPpDY7S7n8mpDOmN'\n",
        "output = 'object_detection.zip'\n",
        "\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "    zip_ref.extractall('datasets')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a47rKtK-u832",
        "outputId": "10dd0ead-ef21-45c6-ca5f-910c5c8983f3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1w0xigcHNMuzeFcj0tPpDY7S7n8mpDOmN\n",
            "To: /content/object_detection.zip\n",
            "100%|| 3.89M/3.89M [00:00<00:00, 82.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the Yaml File for the dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "XTdj1wAv0KjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "# Define the data structure\n",
        "data = {\n",
        "    'model': 'YOLOv5s',\n",
        "    'path': '../datasets/object_detection_data',\n",
        "    'train': 'train/images',  # 47 images\n",
        "    'val': 'val/images',      # 47 images\n",
        "    'names': {\n",
        "        0: 'Mug',\n",
        "        1: 'Keyboard',\n",
        "        2: 'Trainers',\n",
        "        3: 'ZombieThor',\n",
        "        4: 'Mouse',\n",
        "        5: 'Fan',\n",
        "        6: 'Monitor',\n",
        "        7: 'Keys',\n",
        "        8: 'Drawer',\n",
        "        9: 'Sunglasses',\n",
        "        10: 'PlasticBottle'\n",
        "    },\n",
        "    'hyp': {\n",
        "        'lr0': 0.0001,          # initial learning rate\n",
        "        'lrf': 0.2,             # final learning rate\n",
        "        'momentum': 0.937,\n",
        "        'weight_decay': 0.0005,\n",
        "        'warmup_epochs': 3,\n",
        "        'warmup_momentum': 0.8,\n",
        "        'warmup_bias_lr': 0.1\n",
        "    }\n",
        "}\n",
        "\n",
        "# Write the data to a YAML file\n",
        "with open('config.yaml', 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False)\n",
        "\n",
        "print(\"YAML file has been created successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-1HzKEV0Iyb",
        "outputId": "0d12227b-26ae-48e6-ac3a-c19bc5761743"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YAML file has been created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Training the YOLOv5 Model\n",
        "\n",
        "We are now ready to train our YOLOv5 model on the custom dataset.\n",
        "We will use a pre-trained YOLOv5 model and fine-tune it on our dataset.\n",
        "\n",
        "You can choose from different YOLOv5 models like yolov5s (small), yolov5m (medium), yolov5l (large), or yolov5x (extra large).\n",
        "In this example, we will use yolov5s.\n",
        "\n",
        "Training parameters include:\n",
        "- `epochs`: Number of epochs to train the model.\n",
        "- `imgsz`: Image size to resize input images.\n",
        "- `batch`: Batch size.\n"
      ],
      "metadata": {
        "id": "CRg2w-Av1fwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "# model = YOLO('yolov8n.yaml')  # build a new model from scratch\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data='config.yaml', epochs=100, batch=16, imgsz=640)  # train the model"
      ],
      "metadata": {
        "id": "1cLGF-aWqXgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9a5a13-61c9-463b-d4e9-afe7e417a4ab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 6.25M/6.25M [00:00<00:00, 68.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.79  Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=config.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 755k/755k [00:00<00:00, 24.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=11\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    753457  ultralytics.nn.modules.head.Detect           [11, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3,012,993 parameters, 3,012,977 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/object_detection_data/train/labels... 47 images, 0 backgrounds, 0 corrupt: 100%|| 47/47 [00:00<00:00, 1197.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/object_detection_data/train/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/object_detection_data/val/labels... 47 images, 0 backgrounds, 0 corrupt: 100%|| 47/47 [00:00<00:00, 1742.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/object_detection_data/val/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100      2.34G       1.17      3.933      1.304         83        640: 100%|| 3/3 [00:04<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:02<00:00,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137    0.00643      0.568     0.0489     0.0302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      2/100      2.28G      1.261      3.959      1.382         78        640: 100%|| 3/3 [00:01<00:00,  2.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  3.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137    0.00676      0.579     0.0566     0.0385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      3/100      2.28G      1.144      3.923      1.317         61        640: 100%|| 3/3 [00:01<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137    0.00767      0.641     0.0818      0.062\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      4/100       2.3G      1.075      3.818      1.257         99        640: 100%|| 3/3 [00:00<00:00,  3.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137    0.00846      0.727      0.112     0.0892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      5/100      2.27G      1.044      3.722      1.181         92        640: 100%|| 3/3 [00:00<00:00,  4.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137    0.00946      0.755      0.147      0.122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      6/100       2.3G     0.9462      3.478      1.159         86        640: 100%|| 3/3 [00:00<00:00,  4.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137    0.00969      0.806      0.179       0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      7/100       2.3G     0.9478       3.37      1.134         75        640: 100%|| 3/3 [00:00<00:00,  4.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137     0.0104      0.824      0.212      0.173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      8/100      2.15G     0.9548      3.161      1.145         93        640: 100%|| 3/3 [00:00<00:00,  4.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137     0.0111      0.841      0.221      0.182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      9/100      2.29G     0.9838      2.955      1.151         79        640: 100%|| 3/3 [00:00<00:00,  5.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137     0.0122      0.862      0.237      0.193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     10/100      2.28G      1.004      2.796      1.226         72        640: 100%|| 3/3 [00:00<00:00,  3.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137     0.0131      0.907      0.258      0.212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     11/100      2.15G     0.9487      2.613      1.158         90        640: 100%|| 3/3 [00:00<00:00,  3.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137          1     0.0511      0.349      0.285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     12/100      2.29G     0.9151      2.568       1.19         98        640: 100%|| 3/3 [00:00<00:00,  3.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137          1     0.0812      0.363      0.299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     13/100      2.29G     0.9188      2.349      1.178         52        640: 100%|| 3/3 [00:00<00:00,  4.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.993      0.165      0.376      0.309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     14/100       2.3G     0.9503      2.249      1.157         91        640: 100%|| 3/3 [00:00<00:00,  4.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.993      0.171      0.383      0.313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     15/100      2.29G     0.8449      1.986      1.114         96        640: 100%|| 3/3 [00:00<00:00,  5.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  3.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.896      0.184      0.411       0.34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     16/100      2.28G     0.8816      1.941      1.131         80        640: 100%|| 3/3 [00:00<00:00,  5.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.921      0.207      0.423      0.347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     17/100       2.3G     0.9377      1.831      1.179         90        640: 100%|| 3/3 [00:00<00:00,  4.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.933      0.198      0.478       0.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     18/100      2.28G     0.9422      1.942      1.199         97        640: 100%|| 3/3 [00:00<00:00,  3.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.931      0.181      0.533      0.439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     19/100      2.31G     0.9191      1.798      1.127         89        640: 100%|| 3/3 [00:01<00:00,  2.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.855      0.256      0.582      0.489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     20/100      2.31G     0.9072      1.759      1.146         94        640: 100%|| 3/3 [00:00<00:00,  3.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.881      0.349      0.608      0.499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     21/100      2.28G     0.8954      1.658      1.149         95        640: 100%|| 3/3 [00:00<00:00,  4.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  5.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.767       0.39      0.643      0.521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     22/100      2.31G     0.8988       1.56      1.157         94        640: 100%|| 3/3 [00:00<00:00,  4.74it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  5.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.795      0.415      0.672      0.545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     23/100      2.31G     0.8914      1.576      1.122         85        640: 100%|| 3/3 [00:00<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137       0.81      0.461       0.69      0.564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     24/100      2.28G     0.7974      1.379      1.076         96        640: 100%|| 3/3 [00:00<00:00,  4.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.791      0.472      0.721      0.604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     25/100       2.3G     0.8397      1.293      1.109         96        640: 100%|| 3/3 [00:00<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.857      0.519      0.731      0.614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     26/100      2.28G      0.868      1.447      1.135         72        640: 100%|| 3/3 [00:00<00:00,  3.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.819      0.527      0.737      0.603\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     27/100       2.3G     0.8009      1.405      1.115         70        640: 100%|| 3/3 [00:01<00:00,  2.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.825      0.553      0.772      0.622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     28/100      2.29G     0.8282        1.4      1.131         76        640: 100%|| 3/3 [00:01<00:00,  2.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  3.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.775      0.592      0.807      0.648\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     29/100       2.3G     0.8331      1.327       1.08         96        640: 100%|| 3/3 [00:00<00:00,  5.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.775      0.592      0.807      0.648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     30/100       2.3G     0.8454      1.313      1.112         74        640: 100%|| 3/3 [00:00<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  3.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.678      0.632      0.826      0.678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     31/100       2.3G     0.7612      1.275      1.069         89        640: 100%|| 3/3 [00:00<00:00,  4.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.841      0.668      0.848      0.695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     32/100       2.3G        0.8      1.262      1.062         83        640: 100%|| 3/3 [00:00<00:00,  4.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137       0.87      0.721      0.879      0.722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     33/100      2.31G     0.7495      1.163      1.054        108        640: 100%|| 3/3 [00:00<00:00,  5.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137       0.87      0.721      0.879      0.722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     34/100      2.29G     0.8078      1.176      1.077         87        640: 100%|| 3/3 [00:00<00:00,  3.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.864      0.755      0.891      0.747\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     35/100       2.3G     0.7749      1.222      1.091         86        640: 100%|| 3/3 [00:00<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137       0.89      0.792      0.918      0.768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     36/100      2.29G      0.798      1.196      1.096         81        640: 100%|| 3/3 [00:00<00:00,  3.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.921      0.804      0.924      0.767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     37/100       2.3G     0.8346      1.168      1.126         70        640: 100%|| 3/3 [00:00<00:00,  5.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.921      0.804      0.924      0.767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     38/100       2.3G     0.7502       1.23      1.077         76        640: 100%|| 3/3 [00:00<00:00,  5.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.892      0.837      0.935      0.788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     39/100      2.31G     0.7421      1.155      1.068         85        640: 100%|| 3/3 [00:00<00:00,  5.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  5.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.879      0.853      0.942      0.801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     40/100       2.3G     0.7518      1.161      1.081         78        640: 100%|| 3/3 [00:00<00:00,  5.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.871      0.895      0.947      0.802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     41/100       2.3G     0.7602      1.127       1.04         94        640: 100%|| 3/3 [00:00<00:00,  5.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.871      0.895      0.947      0.802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     42/100      2.31G     0.7312      1.136      1.058         71        640: 100%|| 3/3 [00:00<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.897       0.92      0.957      0.823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     43/100      2.28G     0.7774      1.075      1.045         83        640: 100%|| 3/3 [00:00<00:00,  3.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.922      0.905      0.968      0.822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     44/100       2.3G     0.7478      1.084      1.048        105        640: 100%|| 3/3 [00:00<00:00,  3.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.883      0.946      0.976      0.837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     45/100      2.29G     0.7329      1.016      1.039         84        640: 100%|| 3/3 [00:00<00:00,  5.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.883      0.946      0.976      0.837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     46/100      2.31G     0.7594      0.987      1.043        104        640: 100%|| 3/3 [00:00<00:00,  4.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.896      0.964       0.98      0.853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     47/100       2.3G     0.7063      1.019      1.066         74        640: 100%|| 3/3 [00:00<00:00,  4.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.889      0.956      0.976      0.858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     48/100       2.3G      0.723     0.9813      1.041         93        640: 100%|| 3/3 [00:00<00:00,  5.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.884      0.964      0.977       0.85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     49/100      2.31G     0.7165      1.015      1.029         95        640: 100%|| 3/3 [00:00<00:00,  5.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.884      0.964      0.977       0.85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     50/100       2.3G     0.7065      1.017      1.036         79        640: 100%|| 3/3 [00:00<00:00,  4.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.892      0.951      0.977      0.853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     51/100      2.29G      0.744      1.007      1.074         67        640: 100%|| 3/3 [00:00<00:00,  3.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.938      0.928      0.984      0.862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     52/100       2.3G     0.7036     0.9838      1.036        104        640: 100%|| 3/3 [00:00<00:00,  3.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:01<00:00,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.914      0.966      0.983      0.868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     53/100       2.3G     0.7444      1.009      1.092         81        640: 100%|| 3/3 [00:00<00:00,  4.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.914      0.966      0.983      0.868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     54/100      2.29G     0.7189      1.048      1.056         65        640: 100%|| 3/3 [00:00<00:00,  4.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.937      0.963      0.982      0.856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     55/100       2.3G     0.7031      1.022      1.047         91        640: 100%|| 3/3 [00:00<00:00,  4.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.922      0.969      0.987      0.866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     56/100      2.29G     0.6847      1.043      1.055         83        640: 100%|| 3/3 [00:00<00:00,  4.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.926      0.962      0.988      0.873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     57/100      2.28G     0.6909      1.045      1.041         74        640: 100%|| 3/3 [00:00<00:00,  5.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.926      0.962      0.988      0.873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     58/100      2.29G     0.6432     0.9779      1.004         89        640: 100%|| 3/3 [00:00<00:00,  4.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.944      0.966      0.992      0.878\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     59/100       2.3G     0.6814      1.043      1.079         88        640: 100%|| 3/3 [00:00<00:00,  3.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.948      0.974      0.994       0.88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     60/100      2.29G     0.7064     0.9734      1.019        109        640: 100%|| 3/3 [00:00<00:00,  3.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.952      0.976      0.994      0.878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     61/100       2.3G     0.7067     0.9955      1.024         77        640: 100%|| 3/3 [00:00<00:00,  5.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.952      0.976      0.994      0.878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     62/100      2.31G     0.6924     0.9763      1.019         90        640: 100%|| 3/3 [00:00<00:00,  4.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.952      0.983      0.994       0.88\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     63/100      2.18G     0.6244     0.8708      0.982        100        640: 100%|| 3/3 [00:00<00:00,  4.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.933      0.989      0.995      0.885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     64/100       2.3G     0.6758     0.9534      1.026         64        640: 100%|| 3/3 [00:00<00:00,  4.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  5.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137       0.96      0.964      0.995      0.883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     65/100      2.28G     0.6729     0.9377      1.015         94        640: 100%|| 3/3 [00:00<00:00,  5.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137       0.96      0.964      0.995      0.883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     66/100      2.29G     0.6459     0.9076      1.024         72        640: 100%|| 3/3 [00:00<00:00,  5.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.947      0.982      0.994      0.893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     67/100      2.31G     0.5866     0.7864     0.9379        108        640: 100%|| 3/3 [00:00<00:00,  3.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.948      0.983      0.995      0.894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     68/100       2.3G     0.6046     0.8385     0.9715         79        640: 100%|| 3/3 [00:01<00:00,  2.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.948      0.984      0.995      0.898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     69/100      2.29G     0.6703     0.9594      1.064         75        640: 100%|| 3/3 [00:00<00:00,  4.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.948      0.984      0.995      0.898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     70/100       2.3G     0.6108     0.8598     0.9907         90        640: 100%|| 3/3 [00:00<00:00,  4.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  3.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.949      0.996      0.995      0.898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     71/100      2.29G     0.6104     0.8762     0.9722        100        640: 100%|| 3/3 [00:00<00:00,  4.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.953      0.989      0.995      0.897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     72/100       2.3G     0.6457     0.8845      1.022         82        640: 100%|| 3/3 [00:00<00:00,  4.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  5.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.963      0.975      0.995      0.903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     73/100      2.15G        0.6     0.8584     0.9819         85        640: 100%|| 3/3 [00:00<00:00,  5.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.963      0.975      0.995      0.903\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     74/100      2.31G     0.5835     0.8248     0.9793         86        640: 100%|| 3/3 [00:00<00:00,  4.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  3.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.967      0.967      0.994      0.905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     75/100       2.3G     0.6067     0.8332      0.967         83        640: 100%|| 3/3 [00:00<00:00,  3.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.953       0.98      0.995      0.913\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     76/100       2.3G     0.6045     0.8431       1.03         79        640: 100%|| 3/3 [00:00<00:00,  3.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137       0.95      0.982      0.995      0.921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     77/100      2.29G     0.6121     0.8436      1.018         77        640: 100%|| 3/3 [00:00<00:00,  4.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137       0.95      0.982      0.995      0.921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     78/100      2.31G     0.6077     0.8366     0.9977         86        640: 100%|| 3/3 [00:00<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.955      0.971      0.995      0.918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     79/100       2.3G     0.5935     0.8446     0.9706         94        640: 100%|| 3/3 [00:00<00:00,  4.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.966      0.954      0.995      0.919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     80/100      2.14G     0.6244     0.8599      1.003         82        640: 100%|| 3/3 [00:00<00:00,  4.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.954      0.971      0.995       0.92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     81/100      2.29G     0.5985     0.8698     0.9853         82        640: 100%|| 3/3 [00:00<00:00,  5.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  3.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.954      0.971      0.995       0.92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     82/100       2.3G     0.5993     0.7961     0.9493         97        640: 100%|| 3/3 [00:00<00:00,  4.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  3.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.965      0.977      0.995      0.921\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     83/100      2.29G     0.5979     0.8254     0.9746        116        640: 100%|| 3/3 [00:00<00:00,  3.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.971      0.987      0.995      0.922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     84/100      2.28G     0.5744     0.8438     0.9688         59        640: 100%|| 3/3 [00:01<00:00,  2.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.977       0.99      0.995       0.93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     85/100      2.28G      0.591     0.8175     0.9772         90        640: 100%|| 3/3 [00:00<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.977       0.99      0.995       0.93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     86/100      2.19G      0.574     0.8284     0.9766         61        640: 100%|| 3/3 [00:00<00:00,  5.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.978      0.995      0.995      0.934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     87/100      2.28G     0.5921     0.8097     0.9764        107        640: 100%|| 3/3 [00:00<00:00,  4.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.983      0.995      0.995      0.932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     88/100       2.3G     0.5585     0.8567     0.9806         75        640: 100%|| 3/3 [00:00<00:00,  4.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.986      0.996      0.995      0.936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     89/100      2.18G     0.5806     0.8041     0.9621         84        640: 100%|| 3/3 [00:00<00:00,  4.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  3.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.986      0.996      0.995      0.936\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     90/100      2.29G     0.5452     0.7555     0.9487         96        640: 100%|| 3/3 [00:00<00:00,  4.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  3.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.985      0.997      0.995      0.939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     91/100       2.3G     0.4789     0.8892     0.8986         44        640: 100%|| 3/3 [00:02<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:02<00:00,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.984      0.998      0.995      0.948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     92/100       2.3G      0.541     0.9709     0.9342         42        640: 100%|| 3/3 [00:00<00:00,  5.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.984          1      0.995      0.949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     93/100      2.29G     0.5121     0.9838     0.9383         53        640: 100%|| 3/3 [00:00<00:00,  6.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.984          1      0.995      0.949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     94/100      2.27G     0.4768     0.8916     0.8849         49        640: 100%|| 3/3 [00:00<00:00,  5.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.983          1      0.995      0.947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     95/100       2.3G     0.4907     0.8879     0.9117         43        640: 100%|| 3/3 [00:00<00:00,  5.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.982          1      0.995      0.943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     96/100      2.27G     0.5468      0.941      0.985         50        640: 100%|| 3/3 [00:00<00:00,  4.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.982          1      0.995      0.944\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     97/100       2.3G     0.4843     0.8996     0.9023         52        640: 100%|| 3/3 [00:00<00:00,  5.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.982          1      0.995      0.944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     98/100      2.29G     0.4682     0.8754     0.9023         41        640: 100%|| 3/3 [00:00<00:00,  3.47it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.981      0.997      0.995       0.94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     99/100       2.3G     0.5142     0.9072     0.9371         40        640: 100%|| 3/3 [00:00<00:00,  3.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.981      0.998      0.995      0.937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    100/100      2.27G     0.4586     0.8791      0.876         39        640: 100%|| 3/3 [00:00<00:00,  3.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  2.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.981      0.995      0.995      0.934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "100 epochs completed in 0.062 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.79  Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3,007,793 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 2/2 [00:00<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.984          1      0.995       0.95\n",
            "                   Mug         15         15       0.99          1      0.995      0.952\n",
            "              Keyboard         14         15      0.989          1      0.995      0.936\n",
            "              Trainers         13         16          1      0.996      0.995      0.893\n",
            "            ZombieThor         15         15      0.995          1      0.995      0.931\n",
            "                 Mouse         15         15      0.991          1      0.995      0.907\n",
            "                   Fan         10         11      0.987          1      0.995      0.952\n",
            "               Monitor         18         33      0.993          1      0.995      0.983\n",
            "                  Keys          4          4      0.968          1      0.995      0.958\n",
            "                Drawer          3          3      0.947          1      0.995      0.995\n",
            "            Sunglasses          4          4      0.992          1      0.995      0.945\n",
            "         PlasticBottle          6          6      0.973          1      0.995      0.995\n",
            "Speed: 0.2ms preprocess, 2.4ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {0: 'Mug', 1: 'Keyboard', 2: 'Trainers', 3: 'ZombieThor', 4: 'Mouse', 5: 'Fan', 6: 'Monitor',\n",
        "7: 'Keys', 8: 'Drawer', 9: 'Sunglasses', 10: 'PlasticBottle'}\n",
        "print(label_dict.values())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vay00eIQq5ud",
        "outputId": "49cf52ae-b947-4350-e902-e114411f468c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_values(['Mug', 'Keyboard', 'Trainers', 'ZombieThor', 'Mouse', 'Fan', 'Monitor', 'Keys', 'Drawer', 'Sunglasses', 'PlasticBottle'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Evaluate the Model\n",
        "\n",
        "After training, we need to evaluate the model's performance on the test set.\n",
        "YOLOv5 provides built-in functionality to evaluate the model and generate metrics like precision, recall, mAP, etc.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jw1dKvoZ15CY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "metrics = model.val(data='config.yaml', split='val')\n"
      ],
      "metadata": {
        "id": "eY6pENLVq85Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d03c5627-4e90-4f90-847b-42a57dfede15"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.79  Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/object_detection_data/val/labels.cache... 47 images, 0 backgrounds, 0 corrupt: 100%|| 47/47 [00:00<?, ?it/s]\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 3/3 [00:03<00:00,  1.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         47        137      0.984          1      0.995      0.947\n",
            "                   Mug         15         15       0.99          1      0.995      0.952\n",
            "              Keyboard         14         15      0.989          1      0.995      0.936\n",
            "              Trainers         13         16          1      0.996      0.995      0.887\n",
            "            ZombieThor         15         15      0.995          1      0.995      0.907\n",
            "                 Mouse         15         15      0.991          1      0.995      0.907\n",
            "                   Fan         10         11      0.987          1      0.995      0.952\n",
            "               Monitor         18         33      0.993          1      0.995      0.986\n",
            "                  Keys          4          4      0.968          1      0.995      0.958\n",
            "                Drawer          3          3      0.947          1      0.995      0.995\n",
            "            Sunglasses          4          4      0.992          1      0.995      0.945\n",
            "         PlasticBottle          6          6      0.973          1      0.995      0.995\n",
            "Speed: 0.4ms preprocess, 33.8ms inference, 0.0ms loss, 11.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train4\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excellent result almost 98% aggregate."
      ],
      "metadata": {
        "id": "iGdv5cDn7-4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Save the Model\n",
        "Finally, we save the trained model to a file.\n",
        "This allows us to reload the model later for further inference or transfer learning.\n",
        "\n"
      ],
      "metadata": {
        "id": "uoOJBF712cql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('best.pt')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_bIu_0yd2jKt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The model is saved as 'best.pt' and can be reloaded using the YOLO class.\n"
      ],
      "metadata": {
        "id": "cw1c-hck2c89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOU CAN ALSO DOWNLOAD THE SAVED MODEL HERE, uncmment the below\n",
        "# url = 'https://drive.google.com/uc?id=15-wJeOhlRPvy9m3aC9tihdNpntPDwJbn'\n",
        "# output = 'best.pt'\n",
        "\n",
        "# gdown.download(url, output, quiet=False)\n",
        "# print(\"Model has been downloaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3mshYrY_cEm",
        "outputId": "c4d60af0-b3f6-4fef-a51b-c60259ee2d51"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15-wJeOhlRPvy9m3aC9tihdNpntPDwJbn\n",
            "To: /content/best.pt\n",
            "100%|| 6.14M/6.14M [00:01<00:00, 5.25MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model has been downloaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now Let's test our saved model on a recorded video!\n",
        "\n",
        "We are going to download the video from Google drive."
      ],
      "metadata": {
        "id": "G-q4f9Gf7DbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://drive.google.com/uc?id=1RRXF1PbxnGhasqjc5JR6ev0rqcFFzgAk'\n",
        "video_path = 'obj_test_video.mp4'\n",
        "\n",
        "gdown.download(url, video_path, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "yTQ1agmP77E0",
        "outputId": "7df493dd-3232-4843-df53-ce70c7692cce"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RRXF1PbxnGhasqjc5JR6ev0rqcFFzgAk\n",
            "To: /content/obj_test_video.mp4\n",
            "100%|| 46.0M/46.0M [00:00<00:00, 202MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'obj_test_video.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gDMNdaFJ7yyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the YOLO model (using a pre-trained model here)\n",
        "model = YOLO('best.pt')  # Replace with the path to your custom-trained YOLO model if necessary\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "def get_random_colors(num_colors):\n",
        "    colors = []\n",
        "    for _ in range(num_colors):\n",
        "        colors.append((random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)))\n",
        "    return colors\n",
        "\n",
        "\n",
        "colors = get_random_colors(len(model.names))\n",
        "\n",
        "def process_video(video_path, output_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Perform inference using YOLO model\n",
        "        results = model(frame)\n",
        "\n",
        "        # Process the results and draw bounding boxes on the frame\n",
        "        for result in results:\n",
        "            boxes = result.boxes  # Access the detected bounding boxes\n",
        "            for box in boxes:\n",
        "                # Extract the bounding box coordinates, confidence score, and class ID\n",
        "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
        "                conf = box.conf[0].cpu().numpy()\n",
        "                cls = int(box.cls[0].cpu().numpy())  # Convert to int for indexing\n",
        "                label = model.names[cls]  # Get the label/class name\n",
        "                color = colors[cls]\n",
        "                # Draw bounding box and label on the frame\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)\n",
        "                cv2.putText(frame, f'{label} {conf:.2f}', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
        "\n",
        "        # Write the frame to the output video\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# Path to the output video file\n",
        "output_path = 'processed_obj_test_vid.mp4'\n",
        "\n",
        "# Process the video and save the output\n",
        "process_video(video_path, output_path)\n",
        "\n",
        "# Display the processed video\n",
        "from IPython.display import Video\n",
        "Video(output_path, embed=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IAcdtq524ya",
        "outputId": "8d748397-d0a1-4fb3-8f22-eccda37dcd58"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x384 1 Mug, 1 Monitor, 2 PlasticBottles, 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 1 PlasticBottle, 11.9ms\n",
            "Speed: 3.4ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 1 PlasticBottle, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 1 PlasticBottle, 12.2ms\n",
            "Speed: 3.4ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 1 PlasticBottle, 9.4ms\n",
            "Speed: 2.5ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Monitor, 1 PlasticBottle, 9.2ms\n",
            "Speed: 2.6ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Monitor, 1 PlasticBottle, 9.0ms\n",
            "Speed: 2.4ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Monitor, 7.9ms\n",
            "Speed: 2.0ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 1 PlasticBottle, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 14.7ms\n",
            "Speed: 2.7ms preprocess, 14.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 13.1ms\n",
            "Speed: 2.6ms preprocess, 13.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 14.6ms\n",
            "Speed: 2.8ms preprocess, 14.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 14.1ms\n",
            "Speed: 2.8ms preprocess, 14.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 24.1ms\n",
            "Speed: 5.4ms preprocess, 24.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 12.8ms\n",
            "Speed: 2.6ms preprocess, 12.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 21.5ms\n",
            "Speed: 2.5ms preprocess, 21.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 13.7ms\n",
            "Speed: 2.6ms preprocess, 13.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 1 PlasticBottle, 14.2ms\n",
            "Speed: 2.8ms preprocess, 14.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 1 PlasticBottle, 14.9ms\n",
            "Speed: 2.6ms preprocess, 14.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 2 PlasticBottles, 8.3ms\n",
            "Speed: 2.8ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 1 PlasticBottle, 14.4ms\n",
            "Speed: 3.3ms preprocess, 14.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 2 PlasticBottles, 15.6ms\n",
            "Speed: 5.3ms preprocess, 15.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 1 PlasticBottle, 12.8ms\n",
            "Speed: 2.6ms preprocess, 12.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 1 PlasticBottle, 13.2ms\n",
            "Speed: 2.5ms preprocess, 13.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 1 PlasticBottle, 15.7ms\n",
            "Speed: 4.5ms preprocess, 15.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 1 PlasticBottle, 14.5ms\n",
            "Speed: 2.9ms preprocess, 14.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 2 PlasticBottles, 14.7ms\n",
            "Speed: 2.5ms preprocess, 14.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 PlasticBottle, 18.2ms\n",
            "Speed: 2.5ms preprocess, 18.2ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 PlasticBottle, 22.3ms\n",
            "Speed: 2.6ms preprocess, 22.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 PlasticBottle, 18.2ms\n",
            "Speed: 2.7ms preprocess, 18.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 1 PlasticBottle, 14.4ms\n",
            "Speed: 2.7ms preprocess, 14.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 3 Monitors, 1 PlasticBottle, 23.4ms\n",
            "Speed: 2.7ms preprocess, 23.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 3 Monitors, 15.4ms\n",
            "Speed: 2.6ms preprocess, 15.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 3 Monitors, 26.6ms\n",
            "Speed: 2.5ms preprocess, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 16.6ms\n",
            "Speed: 2.6ms preprocess, 16.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 3 Monitors, 20.4ms\n",
            "Speed: 2.6ms preprocess, 20.4ms inference, 21.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 3 Monitors, 26.6ms\n",
            "Speed: 4.6ms preprocess, 26.6ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 3 Monitors, 11.8ms\n",
            "Speed: 2.7ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 3 Monitors, 11.7ms\n",
            "Speed: 4.3ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 3 Monitors, 11.6ms\n",
            "Speed: 3.7ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 3 Monitors, 7.9ms\n",
            "Speed: 2.6ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 3 Monitors, 8.4ms\n",
            "Speed: 3.1ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 3 Monitors, 7.7ms\n",
            "Speed: 3.4ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 3 Monitors, 10.5ms\n",
            "Speed: 2.5ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 3 Monitors, 12.5ms\n",
            "Speed: 2.6ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 4 Monitors, 7.9ms\n",
            "Speed: 2.5ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 3 Monitors, 7.7ms\n",
            "Speed: 2.2ms preprocess, 7.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 3 Monitors, 9.2ms\n",
            "Speed: 3.2ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 2 Monitors, 8.0ms\n",
            "Speed: 2.5ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 2 Monitors, 8.6ms\n",
            "Speed: 2.5ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Fan, 2 Monitors, 12.2ms\n",
            "Speed: 2.6ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Fan, 1 Monitor, 13.1ms\n",
            "Speed: 2.6ms preprocess, 13.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Fan, 1 Monitor, 8.8ms\n",
            "Speed: 2.7ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 8.4ms\n",
            "Speed: 2.6ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 9.8ms\n",
            "Speed: 2.5ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 8.9ms\n",
            "Speed: 2.6ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 7.7ms\n",
            "Speed: 2.0ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 12.1ms\n",
            "Speed: 2.6ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 9.1ms\n",
            "Speed: 3.2ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 9.7ms\n",
            "Speed: 2.2ms preprocess, 9.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 11.4ms\n",
            "Speed: 3.9ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Fan, 1 Monitor, 11.0ms\n",
            "Speed: 2.8ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Monitor, 11.9ms\n",
            "Speed: 6.5ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 1 Monitor, 12.1ms\n",
            "Speed: 2.8ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Mouse, 1 Monitor, 11.2ms\n",
            "Speed: 2.4ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Mouse, 1 Monitor, 14.8ms\n",
            "Speed: 4.3ms preprocess, 14.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Monitor, 12.0ms\n",
            "Speed: 2.7ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Mouse, 2 Monitors, 8.7ms\n",
            "Speed: 4.2ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Mouse, 1 Monitor, 7.9ms\n",
            "Speed: 2.2ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Mouse, 1 Monitor, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Mouse, 1 Monitor, 8.9ms\n",
            "Speed: 2.5ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Mouse, 1 Monitor, 8.9ms\n",
            "Speed: 4.5ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Mouse, 1 Monitor, 9.3ms\n",
            "Speed: 2.6ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Mouse, 1 Monitor, 9.1ms\n",
            "Speed: 3.4ms preprocess, 9.1ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Mouse, 1 Monitor, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Mouse, 1 Monitor, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Mouse, 1 Monitor, 10.0ms\n",
            "Speed: 3.3ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Mouse, 1 Monitor, 8.6ms\n",
            "Speed: 3.1ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Mouse, 1 Monitor, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Monitor, 8.3ms\n",
            "Speed: 2.6ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Monitor, 8.9ms\n",
            "Speed: 3.0ms preprocess, 8.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Monitor, 10.9ms\n",
            "Speed: 2.8ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Monitor, 11.4ms\n",
            "Speed: 2.5ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Monitor, 11.3ms\n",
            "Speed: 2.6ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 11.6ms\n",
            "Speed: 4.2ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 17.5ms\n",
            "Speed: 3.6ms preprocess, 17.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 17.3ms\n",
            "Speed: 2.7ms preprocess, 17.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Monitor, 12.0ms\n",
            "Speed: 2.4ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Monitor, 14.6ms\n",
            "Speed: 2.4ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Monitor, 1 Drawer, 11.9ms\n",
            "Speed: 2.7ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Drawer, 12.1ms\n",
            "Speed: 5.9ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Drawer, 10.2ms\n",
            "Speed: 2.5ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Drawer, 11.8ms\n",
            "Speed: 2.6ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Drawer, 9.2ms\n",
            "Speed: 2.6ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Drawer, 7.7ms\n",
            "Speed: 2.1ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Drawer, 8.6ms\n",
            "Speed: 3.1ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Drawer, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Drawer, 7.9ms\n",
            "Speed: 2.2ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Drawer, 11.0ms\n",
            "Speed: 2.6ms preprocess, 11.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 2 Drawers, 7.6ms\n",
            "Speed: 2.0ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 2 Drawers, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 1 Drawer, 7.5ms\n",
            "Speed: 2.3ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Keyboard, 1 Monitor, 1 Drawer, 7.6ms\n",
            "Speed: 2.1ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Keyboard, 1 Drawer, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Keyboard, 12.0ms\n",
            "Speed: 2.8ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 1 Drawer, 14.1ms\n",
            "Speed: 2.5ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 11.9ms\n",
            "Speed: 2.6ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 12.6ms\n",
            "Speed: 2.5ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 11.2ms\n",
            "Speed: 2.3ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Keyboard, 1 Drawer, 11.4ms\n",
            "Speed: 4.6ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 11.2ms\n",
            "Speed: 3.0ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Keyboard, 12.1ms\n",
            "Speed: 5.9ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 12.4ms\n",
            "Speed: 3.0ms preprocess, 12.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 7.8ms\n",
            "Speed: 2.6ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 7.7ms\n",
            "Speed: 2.0ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Drawers, 7.9ms\n",
            "Speed: 2.0ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Drawer, 7.7ms\n",
            "Speed: 2.1ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 7.9ms\n",
            "Speed: 2.2ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 7.9ms\n",
            "Speed: 2.1ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 8.9ms\n",
            "Speed: 2.4ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 8.3ms\n",
            "Speed: 3.4ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Fan, 1 Drawer, 7.8ms\n",
            "Speed: 2.4ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Drawer, 7.5ms\n",
            "Speed: 2.1ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 7.5ms\n",
            "Speed: 2.0ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 7.6ms\n",
            "Speed: 2.5ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Drawer, 10.3ms\n",
            "Speed: 4.0ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Drawer, 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 11.5ms\n",
            "Speed: 4.3ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Drawer, 12.1ms\n",
            "Speed: 2.5ms preprocess, 12.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 12.7ms\n",
            "Speed: 2.5ms preprocess, 12.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 11.8ms\n",
            "Speed: 2.4ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 12.6ms\n",
            "Speed: 2.4ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Drawer, 11.6ms\n",
            "Speed: 2.4ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Drawer, 12.8ms\n",
            "Speed: 2.6ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Drawer, 10.9ms\n",
            "Speed: 3.8ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Drawer, 12.4ms\n",
            "Speed: 2.7ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Drawer, 10.8ms\n",
            "Speed: 2.4ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Drawer, 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Drawer, 8.6ms\n",
            "Speed: 2.5ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Drawer, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Drawer, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Drawer, 18.8ms\n",
            "Speed: 2.8ms preprocess, 18.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Drawer, 7.8ms\n",
            "Speed: 3.1ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Drawer, 7.8ms\n",
            "Speed: 1.9ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 8.3ms\n",
            "Speed: 2.5ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 9.1ms\n",
            "Speed: 2.4ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Drawer, 7.4ms\n",
            "Speed: 2.0ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 8.9ms\n",
            "Speed: 3.1ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 10.1ms\n",
            "Speed: 3.4ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 10.5ms\n",
            "Speed: 3.2ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 11.7ms\n",
            "Speed: 2.7ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 13.2ms\n",
            "Speed: 3.4ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 11.0ms\n",
            "Speed: 2.6ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 15.6ms\n",
            "Speed: 2.5ms preprocess, 15.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Drawer, 14.1ms\n",
            "Speed: 2.6ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 12.0ms\n",
            "Speed: 2.9ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Drawers, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Drawers, 7.9ms\n",
            "Speed: 2.4ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 8.4ms\n",
            "Speed: 3.1ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 7.5ms\n",
            "Speed: 2.5ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Drawers, 7.8ms\n",
            "Speed: 2.5ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Drawers, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Drawers, 8.8ms\n",
            "Speed: 2.6ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Drawers, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Drawers, 9.6ms\n",
            "Speed: 2.5ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 12.0ms\n",
            "Speed: 3.3ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 9.6ms\n",
            "Speed: 2.6ms preprocess, 9.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 7.8ms\n",
            "Speed: 2.8ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 7.5ms\n",
            "Speed: 2.6ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 8.8ms\n",
            "Speed: 2.7ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 7.6ms\n",
            "Speed: 2.5ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 12.4ms\n",
            "Speed: 5.9ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 11.1ms\n",
            "Speed: 2.7ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 11.7ms\n",
            "Speed: 6.8ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 12.2ms\n",
            "Speed: 2.9ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 10.7ms\n",
            "Speed: 4.5ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 PlasticBottle, 11.7ms\n",
            "Speed: 3.5ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 2 PlasticBottles, 13.3ms\n",
            "Speed: 2.6ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 1 PlasticBottle, 11.6ms\n",
            "Speed: 2.8ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 PlasticBottle, 8.1ms\n",
            "Speed: 4.1ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Monitor, 2 PlasticBottles, 8.4ms\n",
            "Speed: 2.5ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Monitor, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Monitor, 8.3ms\n",
            "Speed: 2.6ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Monitor, 7.9ms\n",
            "Speed: 2.6ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Monitor, 15.4ms\n",
            "Speed: 2.5ms preprocess, 15.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Monitor, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Monitor, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 9.5ms\n",
            "Speed: 2.4ms preprocess, 9.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.5ms\n",
            "Speed: 2.3ms preprocess, 11.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 9.2ms\n",
            "Speed: 2.5ms preprocess, 9.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 9.2ms\n",
            "Speed: 2.4ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.9ms\n",
            "Speed: 2.2ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 8.1ms\n",
            "Speed: 2.0ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 11.5ms\n",
            "Speed: 2.4ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 13.1ms\n",
            "Speed: 3.1ms preprocess, 13.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 11.4ms\n",
            "Speed: 2.6ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 12.6ms\n",
            "Speed: 2.2ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 10.6ms\n",
            "Speed: 2.7ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 16.9ms\n",
            "Speed: 5.9ms preprocess, 16.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 14.9ms\n",
            "Speed: 3.2ms preprocess, 14.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 15.7ms\n",
            "Speed: 2.6ms preprocess, 15.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 13.4ms\n",
            "Speed: 3.2ms preprocess, 13.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 11.3ms\n",
            "Speed: 2.3ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 10.0ms\n",
            "Speed: 2.7ms preprocess, 10.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 11.2ms\n",
            "Speed: 2.4ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 18.6ms\n",
            "Speed: 2.7ms preprocess, 18.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 14.6ms\n",
            "Speed: 2.5ms preprocess, 14.6ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 16.2ms\n",
            "Speed: 3.1ms preprocess, 16.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 4 Monitors, 14.9ms\n",
            "Speed: 3.0ms preprocess, 14.9ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 10.0ms\n",
            "Speed: 4.8ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 13.1ms\n",
            "Speed: 2.9ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 13.1ms\n",
            "Speed: 2.5ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 15.5ms\n",
            "Speed: 2.3ms preprocess, 15.5ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 15.4ms\n",
            "Speed: 2.5ms preprocess, 15.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 14.6ms\n",
            "Speed: 2.4ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 15.0ms\n",
            "Speed: 2.4ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 16.0ms\n",
            "Speed: 2.4ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 9.6ms\n",
            "Speed: 2.9ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.0ms\n",
            "Speed: 3.0ms preprocess, 10.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.7ms\n",
            "Speed: 2.6ms preprocess, 10.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.3ms\n",
            "Speed: 2.8ms preprocess, 10.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.9ms\n",
            "Speed: 2.4ms preprocess, 12.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.9ms\n",
            "Speed: 2.5ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.9ms\n",
            "Speed: 4.7ms preprocess, 12.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 12.3ms\n",
            "Speed: 3.5ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 12.7ms\n",
            "Speed: 2.3ms preprocess, 12.7ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 9.0ms\n",
            "Speed: 2.5ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 9.6ms\n",
            "Speed: 2.4ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 12.5ms\n",
            "Speed: 2.6ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 11.4ms\n",
            "Speed: 4.9ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 15.3ms\n",
            "Speed: 3.9ms preprocess, 15.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 15.2ms\n",
            "Speed: 4.1ms preprocess, 15.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 12.5ms\n",
            "Speed: 2.3ms preprocess, 12.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 9.9ms\n",
            "Speed: 3.5ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 13.7ms\n",
            "Speed: 2.4ms preprocess, 13.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 15.1ms\n",
            "Speed: 2.6ms preprocess, 15.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 16.4ms\n",
            "Speed: 2.7ms preprocess, 16.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 15.4ms\n",
            "Speed: 2.5ms preprocess, 15.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 12.0ms\n",
            "Speed: 2.5ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 1 Drawer, 15.3ms\n",
            "Speed: 2.4ms preprocess, 15.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 16.9ms\n",
            "Speed: 2.6ms preprocess, 16.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 14.5ms\n",
            "Speed: 2.4ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 12.2ms\n",
            "Speed: 9.9ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 14.7ms\n",
            "Speed: 2.4ms preprocess, 14.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 15.3ms\n",
            "Speed: 4.0ms preprocess, 15.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 12.5ms\n",
            "Speed: 3.7ms preprocess, 12.5ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 15.3ms\n",
            "Speed: 2.5ms preprocess, 15.3ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 14.2ms\n",
            "Speed: 2.4ms preprocess, 14.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 16.0ms\n",
            "Speed: 3.6ms preprocess, 16.0ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 16.3ms\n",
            "Speed: 2.6ms preprocess, 16.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 11.5ms\n",
            "Speed: 4.4ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 12.2ms\n",
            "Speed: 2.4ms preprocess, 12.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 11.9ms\n",
            "Speed: 2.7ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 10.9ms\n",
            "Speed: 2.5ms preprocess, 10.9ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 15.8ms\n",
            "Speed: 2.4ms preprocess, 15.8ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 13.9ms\n",
            "Speed: 2.6ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 12.7ms\n",
            "Speed: 2.6ms preprocess, 12.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 13.8ms\n",
            "Speed: 2.4ms preprocess, 13.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 11.1ms\n",
            "Speed: 5.4ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 17.4ms\n",
            "Speed: 4.4ms preprocess, 17.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 1 Drawer, 14.7ms\n",
            "Speed: 5.0ms preprocess, 14.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 12.2ms\n",
            "Speed: 3.8ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 19.5ms\n",
            "Speed: 3.6ms preprocess, 19.5ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 18.9ms\n",
            "Speed: 2.4ms preprocess, 18.9ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 15.3ms\n",
            "Speed: 2.3ms preprocess, 15.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 15.6ms\n",
            "Speed: 2.6ms preprocess, 15.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 17.6ms\n",
            "Speed: 2.4ms preprocess, 17.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 11.9ms\n",
            "Speed: 2.3ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 13.2ms\n",
            "Speed: 2.4ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 13.5ms\n",
            "Speed: 3.9ms preprocess, 13.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.8ms\n",
            "Speed: 2.4ms preprocess, 12.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 11.4ms\n",
            "Speed: 2.9ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 11.4ms\n",
            "Speed: 2.8ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 10.4ms\n",
            "Speed: 5.9ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 1 Drawer, 16.3ms\n",
            "Speed: 2.4ms preprocess, 16.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 2 Drawers, 11.5ms\n",
            "Speed: 2.5ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 2 Drawers, 11.0ms\n",
            "Speed: 2.5ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 1 Drawer, 15.2ms\n",
            "Speed: 4.5ms preprocess, 15.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 14.3ms\n",
            "Speed: 2.5ms preprocess, 14.3ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 13.4ms\n",
            "Speed: 2.6ms preprocess, 13.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.2ms\n",
            "Speed: 2.7ms preprocess, 12.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 13.7ms\n",
            "Speed: 2.3ms preprocess, 13.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Drawers, 16.2ms\n",
            "Speed: 2.3ms preprocess, 16.2ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 12.4ms\n",
            "Speed: 3.2ms preprocess, 12.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 13.0ms\n",
            "Speed: 2.6ms preprocess, 13.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 12.3ms\n",
            "Speed: 2.4ms preprocess, 12.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 1 Drawer, 13.1ms\n",
            "Speed: 2.7ms preprocess, 13.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 13.2ms\n",
            "Speed: 2.5ms preprocess, 13.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 11.2ms\n",
            "Speed: 2.3ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 11.4ms\n",
            "Speed: 2.9ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 11.6ms\n",
            "Speed: 2.4ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 1 Drawer, 11.2ms\n",
            "Speed: 5.4ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 12.3ms\n",
            "Speed: 2.4ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Drawer, 11.8ms\n",
            "Speed: 2.4ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 12.5ms\n",
            "Speed: 2.6ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 1 Drawer, 12.7ms\n",
            "Speed: 2.5ms preprocess, 12.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 1 Drawer, 15.9ms\n",
            "Speed: 2.5ms preprocess, 15.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 14.8ms\n",
            "Speed: 4.1ms preprocess, 14.8ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 1 Drawer, 19.3ms\n",
            "Speed: 2.4ms preprocess, 19.3ms inference, 6.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 16.6ms\n",
            "Speed: 5.1ms preprocess, 16.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 18.4ms\n",
            "Speed: 3.6ms preprocess, 18.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 1 Drawer, 13.5ms\n",
            "Speed: 2.5ms preprocess, 13.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 13.9ms\n",
            "Speed: 4.9ms preprocess, 13.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 14.3ms\n",
            "Speed: 2.4ms preprocess, 14.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 1 Drawer, 11.7ms\n",
            "Speed: 4.0ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 10.9ms\n",
            "Speed: 3.4ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 11.0ms\n",
            "Speed: 3.5ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 1 Drawer, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 14.1ms\n",
            "Speed: 2.7ms preprocess, 14.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 1 Drawer, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 12.6ms\n",
            "Speed: 2.6ms preprocess, 12.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 13.1ms\n",
            "Speed: 2.4ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 1 Drawer, 14.7ms\n",
            "Speed: 2.6ms preprocess, 14.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 2 Drawers, 18.1ms\n",
            "Speed: 2.5ms preprocess, 18.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 13.8ms\n",
            "Speed: 6.8ms preprocess, 13.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 16.8ms\n",
            "Speed: 4.1ms preprocess, 16.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 16.7ms\n",
            "Speed: 3.9ms preprocess, 16.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 14.8ms\n",
            "Speed: 4.2ms preprocess, 14.8ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 14.1ms\n",
            "Speed: 5.7ms preprocess, 14.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 24.5ms\n",
            "Speed: 2.5ms preprocess, 24.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 18.4ms\n",
            "Speed: 2.6ms preprocess, 18.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 16.1ms\n",
            "Speed: 2.7ms preprocess, 16.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 13.5ms\n",
            "Speed: 2.6ms preprocess, 13.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 12.8ms\n",
            "Speed: 2.5ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 Drawer, 22.3ms\n",
            "Speed: 5.0ms preprocess, 22.3ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 13.4ms\n",
            "Speed: 2.6ms preprocess, 13.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 14.6ms\n",
            "Speed: 6.7ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 17.5ms\n",
            "Speed: 2.5ms preprocess, 17.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.3ms\n",
            "Speed: 2.4ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 15.7ms\n",
            "Speed: 3.9ms preprocess, 15.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 21.0ms\n",
            "Speed: 2.5ms preprocess, 21.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 19.7ms\n",
            "Speed: 2.6ms preprocess, 19.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 18.7ms\n",
            "Speed: 3.7ms preprocess, 18.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 14.4ms\n",
            "Speed: 2.9ms preprocess, 14.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 14.6ms\n",
            "Speed: 3.2ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.9ms\n",
            "Speed: 2.6ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.0ms\n",
            "Speed: 4.3ms preprocess, 12.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.3ms\n",
            "Speed: 4.3ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.3ms\n",
            "Speed: 3.7ms preprocess, 11.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.4ms\n",
            "Speed: 2.6ms preprocess, 11.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.7ms\n",
            "Speed: 2.5ms preprocess, 11.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.6ms\n",
            "Speed: 2.6ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 12.2ms\n",
            "Speed: 2.5ms preprocess, 12.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 (no detections), 13.0ms\n",
            "Speed: 2.5ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 10.6ms\n",
            "Speed: 2.5ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 18.7ms\n",
            "Speed: 2.4ms preprocess, 18.7ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 17.5ms\n",
            "Speed: 2.6ms preprocess, 17.5ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 14.3ms\n",
            "Speed: 2.8ms preprocess, 14.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 15.1ms\n",
            "Speed: 2.8ms preprocess, 15.1ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Mouses, 3 Monitors, 20.2ms\n",
            "Speed: 2.5ms preprocess, 20.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 18.4ms\n",
            "Speed: 3.5ms preprocess, 18.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 17.6ms\n",
            "Speed: 5.1ms preprocess, 17.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Mouses, 3 Monitors, 14.2ms\n",
            "Speed: 2.4ms preprocess, 14.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 14.7ms\n",
            "Speed: 2.4ms preprocess, 14.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mouse, 3 Monitors, 13.2ms\n",
            "Speed: 2.6ms preprocess, 13.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 13.3ms\n",
            "Speed: 2.4ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mouse, 2 Monitors, 13.5ms\n",
            "Speed: 2.6ms preprocess, 13.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 14.2ms\n",
            "Speed: 3.1ms preprocess, 14.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 13.2ms\n",
            "Speed: 2.9ms preprocess, 13.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mouse, 2 Monitors, 9.5ms\n",
            "Speed: 2.6ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 4 Monitors, 11.6ms\n",
            "Speed: 2.5ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 4 Monitors, 9.9ms\n",
            "Speed: 2.6ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 10.2ms\n",
            "Speed: 2.8ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 14.2ms\n",
            "Speed: 3.0ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 1 PlasticBottle, 12.1ms\n",
            "Speed: 4.0ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 1 PlasticBottle, 11.0ms\n",
            "Speed: 2.8ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 PlasticBottle, 12.2ms\n",
            "Speed: 5.0ms preprocess, 12.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Monitor, 1 PlasticBottle, 18.1ms\n",
            "Speed: 2.8ms preprocess, 18.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 1 PlasticBottle, 11.3ms\n",
            "Speed: 3.8ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 1 PlasticBottle, 17.2ms\n",
            "Speed: 2.4ms preprocess, 17.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 1 PlasticBottle, 7.8ms\n",
            "Speed: 2.1ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 1 PlasticBottle, 9.5ms\n",
            "Speed: 2.4ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Monitors, 1 PlasticBottle, 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 3 PlasticBottles, 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 2 PlasticBottles, 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 3 PlasticBottles, 7.3ms\n",
            "Speed: 2.2ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 2 PlasticBottles, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 2 Monitors, 2 PlasticBottles, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 3 PlasticBottles, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 2 PlasticBottles, 7.6ms\n",
            "Speed: 2.6ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 3 Monitors, 2 PlasticBottles, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 3 Monitors, 3 PlasticBottles, 8.8ms\n",
            "Speed: 2.7ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 3 Monitors, 2 PlasticBottles, 7.4ms\n",
            "Speed: 2.9ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 3 Monitors, 2 PlasticBottles, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 3 Monitors, 1 PlasticBottle, 7.8ms\n",
            "Speed: 2.3ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 2 Monitors, 3 PlasticBottles, 8.6ms\n",
            "Speed: 3.1ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 2 PlasticBottles, 10.6ms\n",
            "Speed: 2.5ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Monitors, 2 PlasticBottles, 11.5ms\n",
            "Speed: 2.6ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 3 Monitors, 2 PlasticBottles, 13.3ms\n",
            "Speed: 2.3ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 3 Monitors, 3 PlasticBottles, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 3 Monitors, 2 PlasticBottles, 11.1ms\n",
            "Speed: 3.4ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 3 Monitors, 3 PlasticBottles, 11.2ms\n",
            "Speed: 4.2ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 3 Monitors, 2 PlasticBottles, 19.4ms\n",
            "Speed: 3.0ms preprocess, 19.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 3 Monitors, 2 PlasticBottles, 19.5ms\n",
            "Speed: 2.4ms preprocess, 19.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 2 Monitors, 1 PlasticBottle, 12.2ms\n",
            "Speed: 2.7ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 3 Monitors, 2 PlasticBottles, 8.0ms\n",
            "Speed: 2.5ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 3 Monitors, 2 PlasticBottles, 9.2ms\n",
            "Speed: 2.5ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 4 Monitors, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 4 Monitors, 11.5ms\n",
            "Speed: 2.0ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 3 Monitors, 7.7ms\n",
            "Speed: 2.4ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 3 Monitors, 1 PlasticBottle, 8.3ms\n",
            "Speed: 4.6ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 3 Monitors, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 5 Monitors, 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 2 Fans, 4 Monitors, 8.1ms\n",
            "Speed: 3.1ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Fan, 3 Monitors, 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 3 Monitors, 10.6ms\n",
            "Speed: 2.8ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 4 Monitors, 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 3 Monitors, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 2 Monitors, 10.5ms\n",
            "Speed: 2.4ms preprocess, 10.5ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Fan, 3 Monitors, 12.8ms\n",
            "Speed: 2.9ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 2 Fans, 3 Monitors, 12.4ms\n",
            "Speed: 3.1ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 3 Monitors, 12.6ms\n",
            "Speed: 8.8ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 3 Monitors, 11.2ms\n",
            "Speed: 2.6ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Fan, 3 Monitors, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 4 Monitors, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 2 Monitors, 11.9ms\n",
            "Speed: 2.6ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 1 Fan, 2 Monitors, 11.7ms\n",
            "Speed: 2.6ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Fan, 2 Monitors, 9.5ms\n",
            "Speed: 2.4ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 1 Fan, 2 Monitors, 10.4ms\n",
            "Speed: 2.5ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Fan, 2 Monitors, 7.7ms\n",
            "Speed: 2.0ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 1 Mouse, 1 Fan, 1 Monitor, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 1 Fan, 1 Monitor, 10.4ms\n",
            "Speed: 2.5ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 1 Fan, 1 Monitor, 9.7ms\n",
            "Speed: 2.4ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Keyboards, 2 Fans, 1 Monitor, 11.8ms\n",
            "Speed: 2.5ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 1 Fan, 2 Monitors, 9.9ms\n",
            "Speed: 2.5ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Fan, 2 Monitors, 15.2ms\n",
            "Speed: 2.5ms preprocess, 15.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Monitor, 11.9ms\n",
            "Speed: 3.4ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 1 Fan, 1 Monitor, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 1 Fan, 1 Monitor, 7.6ms\n",
            "Speed: 2.3ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 1 Mouse, 1 Fan, 1 Monitor, 7.7ms\n",
            "Speed: 3.0ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 2 Fans, 1 Monitor, 7.9ms\n",
            "Speed: 2.1ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 2 Fans, 1 Monitor, 12.7ms\n",
            "Speed: 3.1ms preprocess, 12.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 1 Monitor, 11.7ms\n",
            "Speed: 4.2ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 1 Monitor, 11.0ms\n",
            "Speed: 4.8ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 1 Monitor, 10.2ms\n",
            "Speed: 4.6ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 2 Fans, 1 Monitor, 13.4ms\n",
            "Speed: 2.4ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 ZombieThor, 1 Fan, 1 Monitor, 13.3ms\n",
            "Speed: 2.5ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 2 Fans, 1 Monitor, 11.4ms\n",
            "Speed: 2.9ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 2 Fans, 1 Monitor, 11.8ms\n",
            "Speed: 2.7ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 ZombieThors, 1 Fan, 1 Monitor, 9.6ms\n",
            "Speed: 2.4ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Fan, 1 Monitor, 12.6ms\n",
            "Speed: 4.5ms preprocess, 12.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Fan, 1 Monitor, 7.9ms\n",
            "Speed: 3.6ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Fan, 2 Monitors, 9.9ms\n",
            "Speed: 2.4ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Fan, 1 Monitor, 9.9ms\n",
            "Speed: 2.6ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Fan, 1 Monitor, 9.8ms\n",
            "Speed: 2.5ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 2 Fans, 2 Monitors, 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 2 Monitors, 7.7ms\n",
            "Speed: 2.7ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 8.6ms\n",
            "Speed: 2.7ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 7.7ms\n",
            "Speed: 2.2ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 2 Monitors, 7.9ms\n",
            "Speed: 2.5ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 2 Monitors, 8.1ms\n",
            "Speed: 2.9ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 2 Monitors, 7.4ms\n",
            "Speed: 2.1ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 2 Monitors, 9.6ms\n",
            "Speed: 2.6ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 2 Monitors, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 2 Monitors, 12.3ms\n",
            "Speed: 2.7ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 2 Monitors, 12.6ms\n",
            "Speed: 2.4ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 2 Monitors, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 ZombieThors, 1 Fan, 2 Monitors, 19.5ms\n",
            "Speed: 3.3ms preprocess, 19.5ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 2 Fans, 2 Monitors, 13.8ms\n",
            "Speed: 3.8ms preprocess, 13.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 2 Monitors, 13.6ms\n",
            "Speed: 3.9ms preprocess, 13.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 ZombieThors, 1 Fan, 2 Monitors, 9.7ms\n",
            "Speed: 2.6ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 ZombieThors, 2 Fans, 2 Monitors, 8.3ms\n",
            "Speed: 2.8ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 2 Monitors, 8.1ms\n",
            "Speed: 2.5ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 11.4ms\n",
            "Speed: 2.5ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 2 Monitors, 11.2ms\n",
            "Speed: 2.4ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 2 Monitors, 8.4ms\n",
            "Speed: 4.3ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 2 Monitors, 8.1ms\n",
            "Speed: 6.4ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 7.5ms\n",
            "Speed: 2.5ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 10.5ms\n",
            "Speed: 2.4ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 9.3ms\n",
            "Speed: 2.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 9.3ms\n",
            "Speed: 2.6ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 ZombieThors, 1 Fan, 1 Monitor, 12.5ms\n",
            "Speed: 4.2ms preprocess, 12.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 12.7ms\n",
            "Speed: 2.5ms preprocess, 12.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 13.7ms\n",
            "Speed: 2.4ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 10.5ms\n",
            "Speed: 4.1ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 10.9ms\n",
            "Speed: 2.8ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 2 Fans, 1 Monitor, 10.0ms\n",
            "Speed: 3.4ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Mouse, 1 Fan, 1 Monitor, 17.3ms\n",
            "Speed: 4.0ms preprocess, 17.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 10.9ms\n",
            "Speed: 6.6ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 2 Monitors, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 9.6ms\n",
            "Speed: 2.8ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 11.0ms\n",
            "Speed: 2.7ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 1 Monitor, 13.3ms\n",
            "Speed: 2.5ms preprocess, 13.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Fan, 1 Monitor, 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Fan, 1 Monitor, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Fans, 1 Monitor, 9.0ms\n",
            "Speed: 4.7ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 9.1ms\n",
            "Speed: 2.4ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Fans, 1 Monitor, 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 10.9ms\n",
            "Speed: 2.6ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 7.8ms\n",
            "Speed: 2.3ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 8.1ms\n",
            "Speed: 3.1ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 9.0ms\n",
            "Speed: 3.6ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 8.3ms\n",
            "Speed: 2.6ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 12.5ms\n",
            "Speed: 2.6ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 12.3ms\n",
            "Speed: 2.6ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 10.7ms\n",
            "Speed: 4.6ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 13.0ms\n",
            "Speed: 2.5ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 11.6ms\n",
            "Speed: 2.7ms preprocess, 11.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 13.2ms\n",
            "Speed: 5.7ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 17.9ms\n",
            "Speed: 3.9ms preprocess, 17.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 ZombieThors, 1 Monitor, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 7.8ms\n",
            "Speed: 2.8ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 12.3ms\n",
            "Speed: 2.6ms preprocess, 12.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 9.9ms\n",
            "Speed: 2.7ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 11.3ms\n",
            "Speed: 2.6ms preprocess, 11.3ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 8.8ms\n",
            "Speed: 2.6ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Monitor, 14.7ms\n",
            "Speed: 3.1ms preprocess, 14.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 10.4ms\n",
            "Speed: 3.0ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 11.3ms\n",
            "Speed: 4.2ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 10.9ms\n",
            "Speed: 2.7ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 10.1ms\n",
            "Speed: 2.7ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 11.6ms\n",
            "Speed: 2.7ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Fan, 1 Monitor, 13.2ms\n",
            "Speed: 4.1ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Fan, 2 Monitors, 15.9ms\n",
            "Speed: 3.0ms preprocess, 15.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Fan, 1 Monitor, 13.0ms\n",
            "Speed: 3.6ms preprocess, 13.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Fan, 1 Monitor, 16.5ms\n",
            "Speed: 2.6ms preprocess, 16.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Fan, 1 Monitor, 13.3ms\n",
            "Speed: 2.7ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Fan, 1 Monitor, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Fan, 1 Monitor, 8.6ms\n",
            "Speed: 6.8ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Fan, 1 Monitor, 11.0ms\n",
            "Speed: 2.6ms preprocess, 11.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Fan, 1 Monitor, 10.8ms\n",
            "Speed: 2.7ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Fan, 1 Monitor, 7.7ms\n",
            "Speed: 2.5ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 15.5ms\n",
            "Speed: 2.5ms preprocess, 15.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 10.1ms\n",
            "Speed: 2.7ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 10.1ms\n",
            "Speed: 2.8ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 11.7ms\n",
            "Speed: 2.6ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 10.9ms\n",
            "Speed: 2.5ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 11.7ms\n",
            "Speed: 2.3ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 7.4ms\n",
            "Speed: 5.7ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 9.8ms\n",
            "Speed: 2.6ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 10.9ms\n",
            "Speed: 2.6ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 13.5ms\n",
            "Speed: 4.5ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 11.8ms\n",
            "Speed: 2.5ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 15.3ms\n",
            "Speed: 3.0ms preprocess, 15.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 12.8ms\n",
            "Speed: 4.3ms preprocess, 12.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 12.8ms\n",
            "Speed: 2.7ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 13.7ms\n",
            "Speed: 4.5ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 8.3ms\n",
            "Speed: 2.5ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 9.7ms\n",
            "Speed: 2.5ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Monitor, 9.3ms\n",
            "Speed: 2.6ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 9.5ms\n",
            "Speed: 3.3ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Monitor, 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 9.8ms\n",
            "Speed: 3.3ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 20.2ms\n",
            "Speed: 2.7ms preprocess, 20.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 9.9ms\n",
            "Speed: 5.2ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 11.7ms\n",
            "Speed: 2.5ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Monitor, 9.4ms\n",
            "Speed: 4.4ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 7.9ms\n",
            "Speed: 2.4ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 10.3ms\n",
            "Speed: 2.7ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 15.1ms\n",
            "Speed: 3.6ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 ZombieThors, 1 Monitor, 11.8ms\n",
            "Speed: 2.5ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 ZombieThors, 1 Monitor, 16.3ms\n",
            "Speed: 2.4ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 ZombieThors, 1 Monitor, 11.1ms\n",
            "Speed: 2.5ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 ZombieThors, 1 Monitor, 15.4ms\n",
            "Speed: 2.7ms preprocess, 15.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 ZombieThors, 1 Monitor, 11.7ms\n",
            "Speed: 2.9ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 ZombieThors, 1 Monitor, 11.4ms\n",
            "Speed: 6.5ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 8.8ms\n",
            "Speed: 4.1ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 ZombieThors, 1 Monitor, 8.5ms\n",
            "Speed: 4.2ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 ZombieThors, 1 Monitor, 7.9ms\n",
            "Speed: 2.9ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 2 ZombieThors, 1 Monitor, 8.5ms\n",
            "Speed: 2.9ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 2 ZombieThors, 1 Monitor, 8.6ms\n",
            "Speed: 3.9ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 7.6ms\n",
            "Speed: 2.5ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Monitor, 9.7ms\n",
            "Speed: 3.3ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Monitor, 20.7ms\n",
            "Speed: 2.4ms preprocess, 20.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Monitor, 10.5ms\n",
            "Speed: 2.5ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Monitor, 12.5ms\n",
            "Speed: 2.5ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Monitor, 14.0ms\n",
            "Speed: 2.5ms preprocess, 14.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Monitor, 12.5ms\n",
            "Speed: 2.5ms preprocess, 12.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Monitor, 12.7ms\n",
            "Speed: 2.7ms preprocess, 12.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Monitor, 17.1ms\n",
            "Speed: 2.5ms preprocess, 17.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Monitor, 16.3ms\n",
            "Speed: 2.5ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Monitor, 17.1ms\n",
            "Speed: 2.5ms preprocess, 17.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 17.0ms\n",
            "Speed: 2.5ms preprocess, 17.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 23.1ms\n",
            "Speed: 2.7ms preprocess, 23.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 18.8ms\n",
            "Speed: 6.7ms preprocess, 18.8ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 13.8ms\n",
            "Speed: 4.9ms preprocess, 13.8ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 15.7ms\n",
            "Speed: 4.4ms preprocess, 15.7ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 15.0ms\n",
            "Speed: 4.2ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 21.3ms\n",
            "Speed: 2.5ms preprocess, 21.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 23.8ms\n",
            "Speed: 2.5ms preprocess, 23.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 18.3ms\n",
            "Speed: 2.5ms preprocess, 18.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 13.6ms\n",
            "Speed: 2.5ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 11.9ms\n",
            "Speed: 2.4ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 15.6ms\n",
            "Speed: 2.4ms preprocess, 15.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 16.6ms\n",
            "Speed: 2.5ms preprocess, 16.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 13.1ms\n",
            "Speed: 2.6ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 19.2ms\n",
            "Speed: 2.5ms preprocess, 19.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 17.3ms\n",
            "Speed: 2.4ms preprocess, 17.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 13.8ms\n",
            "Speed: 2.4ms preprocess, 13.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 12.0ms\n",
            "Speed: 2.5ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 10.7ms\n",
            "Speed: 4.1ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 14.6ms\n",
            "Speed: 2.3ms preprocess, 14.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 10.2ms\n",
            "Speed: 2.7ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 9.9ms\n",
            "Speed: 2.4ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 9.7ms\n",
            "Speed: 2.8ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 17.3ms\n",
            "Speed: 2.8ms preprocess, 17.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 10.4ms\n",
            "Speed: 2.9ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 12.5ms\n",
            "Speed: 2.5ms preprocess, 12.5ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 10.2ms\n",
            "Speed: 2.5ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 11.2ms\n",
            "Speed: 2.7ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 11.1ms\n",
            "Speed: 2.4ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Monitor, 14.4ms\n",
            "Speed: 2.8ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 18.1ms\n",
            "Speed: 3.4ms preprocess, 18.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Fan, 1 Monitor, 20.1ms\n",
            "Speed: 2.7ms preprocess, 20.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Fan, 1 Monitor, 15.6ms\n",
            "Speed: 4.4ms preprocess, 15.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Fan, 1 Monitor, 17.4ms\n",
            "Speed: 4.8ms preprocess, 17.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Fan, 1 Monitor, 13.5ms\n",
            "Speed: 2.7ms preprocess, 13.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 1 Monitor, 17.8ms\n",
            "Speed: 2.7ms preprocess, 17.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 13.6ms\n",
            "Speed: 3.2ms preprocess, 13.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 11.2ms\n",
            "Speed: 3.8ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 12.8ms\n",
            "Speed: 2.4ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 12.9ms\n",
            "Speed: 2.3ms preprocess, 12.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 14.3ms\n",
            "Speed: 2.4ms preprocess, 14.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 16.6ms\n",
            "Speed: 7.4ms preprocess, 16.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 18.9ms\n",
            "Speed: 2.5ms preprocess, 18.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 16.4ms\n",
            "Speed: 3.9ms preprocess, 16.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 14.2ms\n",
            "Speed: 2.5ms preprocess, 14.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 16.6ms\n",
            "Speed: 3.8ms preprocess, 16.6ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 18.6ms\n",
            "Speed: 2.5ms preprocess, 18.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 13.7ms\n",
            "Speed: 2.6ms preprocess, 13.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 1 Monitor, 20.9ms\n",
            "Speed: 3.6ms preprocess, 20.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 1 Monitor, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 1 Monitor, 14.4ms\n",
            "Speed: 2.9ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 1 Monitor, 12.9ms\n",
            "Speed: 2.4ms preprocess, 12.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 1 Monitor, 13.7ms\n",
            "Speed: 2.3ms preprocess, 13.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 1 Monitor, 12.5ms\n",
            "Speed: 2.5ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Fan, 1 Monitor, 13.5ms\n",
            "Speed: 2.6ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Fan, 1 Monitor, 11.3ms\n",
            "Speed: 3.6ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Fan, 1 Monitor, 15.2ms\n",
            "Speed: 2.4ms preprocess, 15.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Fan, 1 Monitor, 13.0ms\n",
            "Speed: 3.8ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Fan, 1 Monitor, 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 ZombieThor, 1 Fan, 1 Monitor, 13.5ms\n",
            "Speed: 2.7ms preprocess, 13.5ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 14.5ms\n",
            "Speed: 2.6ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 12.7ms\n",
            "Speed: 2.6ms preprocess, 12.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 13.8ms\n",
            "Speed: 2.6ms preprocess, 13.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 13.6ms\n",
            "Speed: 2.4ms preprocess, 13.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 16.3ms\n",
            "Speed: 2.6ms preprocess, 16.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 12.8ms\n",
            "Speed: 2.6ms preprocess, 12.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 11.8ms\n",
            "Speed: 2.4ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 16.7ms\n",
            "Speed: 2.5ms preprocess, 16.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 ZombieThor, 1 Fan, 1 Monitor, 11.5ms\n",
            "Speed: 2.5ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Fan, 1 Monitor, 11.1ms\n",
            "Speed: 2.4ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mouse, 1 Fan, 1 Monitor, 17.7ms\n",
            "Speed: 2.5ms preprocess, 17.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 11.0ms\n",
            "Speed: 6.4ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 12.6ms\n",
            "Speed: 2.3ms preprocess, 12.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Monitor, 17.7ms\n",
            "Speed: 4.9ms preprocess, 17.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Monitor, 12.8ms\n",
            "Speed: 3.0ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Monitor, 12.4ms\n",
            "Speed: 3.7ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 1 Monitor, 12.6ms\n",
            "Speed: 2.4ms preprocess, 12.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Keyboards, 1 Mouse, 1 Monitor, 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Keyboards, 1 Mouse, 1 Monitor, 17.5ms\n",
            "Speed: 4.5ms preprocess, 17.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Keyboards, 1 Mouse, 1 Monitor, 13.8ms\n",
            "Speed: 4.8ms preprocess, 13.8ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 4 Keyboards, 1 Mouse, 18.9ms\n",
            "Speed: 2.4ms preprocess, 18.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Keyboards, 1 Mouse, 20.2ms\n",
            "Speed: 2.9ms preprocess, 20.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 4 Keyboards, 1 Mouse, 14.0ms\n",
            "Speed: 2.4ms preprocess, 14.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 4 Keyboards, 1 Mouse, 16.7ms\n",
            "Speed: 2.5ms preprocess, 16.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 4 Keyboards, 1 Mouse, 18.9ms\n",
            "Speed: 7.0ms preprocess, 18.9ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Keyboards, 1 Mouse, 16.5ms\n",
            "Speed: 4.7ms preprocess, 16.5ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Keyboards, 1 Mouse, 15.1ms\n",
            "Speed: 2.4ms preprocess, 15.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Keyboards, 1 Mouse, 17.2ms\n",
            "Speed: 6.0ms preprocess, 17.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 3 Keyboards, 1 Mouse, 13.7ms\n",
            "Speed: 2.5ms preprocess, 13.7ms inference, 5.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Keyboard, 13.2ms\n",
            "Speed: 2.8ms preprocess, 13.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 11.9ms\n",
            "Speed: 2.4ms preprocess, 11.9ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 11.8ms\n",
            "Speed: 2.6ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 12.5ms\n",
            "Speed: 2.3ms preprocess, 12.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 22.8ms\n",
            "Speed: 4.7ms preprocess, 22.8ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 23.7ms\n",
            "Speed: 2.9ms preprocess, 23.7ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 16.2ms\n",
            "Speed: 2.5ms preprocess, 16.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 14.4ms\n",
            "Speed: 2.4ms preprocess, 14.4ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 13.0ms\n",
            "Speed: 2.5ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 12.1ms\n",
            "Speed: 2.9ms preprocess, 12.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 12.2ms\n",
            "Speed: 2.8ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 11.9ms\n",
            "Speed: 2.7ms preprocess, 11.9ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 12.6ms\n",
            "Speed: 2.6ms preprocess, 12.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 13.0ms\n",
            "Speed: 2.3ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Keyboard, 1 Mouse, 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Mug, 1 Keyboard, 1 Mouse, 13.5ms\n",
            "Speed: 4.8ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 14.1ms\n",
            "Speed: 2.6ms preprocess, 14.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 14.4ms\n",
            "Speed: 2.4ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 18.3ms\n",
            "Speed: 2.4ms preprocess, 18.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 12.4ms\n",
            "Speed: 2.3ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 1 Fan, 1 Monitor, 14.5ms\n",
            "Speed: 2.6ms preprocess, 14.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 13.0ms\n",
            "Speed: 2.8ms preprocess, 13.0ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 14.5ms\n",
            "Speed: 2.6ms preprocess, 14.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 15.1ms\n",
            "Speed: 2.4ms preprocess, 15.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 14.5ms\n",
            "Speed: 2.6ms preprocess, 14.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 14.6ms\n",
            "Speed: 2.8ms preprocess, 14.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 12.0ms\n",
            "Speed: 2.3ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 11.7ms\n",
            "Speed: 2.4ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 14.8ms\n",
            "Speed: 2.7ms preprocess, 14.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 11.8ms\n",
            "Speed: 2.5ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 12.8ms\n",
            "Speed: 2.6ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 14.5ms\n",
            "Speed: 2.4ms preprocess, 14.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 18.5ms\n",
            "Speed: 2.6ms preprocess, 18.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 13.4ms\n",
            "Speed: 2.5ms preprocess, 13.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 11.7ms\n",
            "Speed: 2.8ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 12.2ms\n",
            "Speed: 2.5ms preprocess, 12.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 14.3ms\n",
            "Speed: 2.8ms preprocess, 14.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 15.3ms\n",
            "Speed: 2.7ms preprocess, 15.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 14.1ms\n",
            "Speed: 2.6ms preprocess, 14.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 11.5ms\n",
            "Speed: 2.6ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 12.4ms\n",
            "Speed: 2.7ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 15.5ms\n",
            "Speed: 2.4ms preprocess, 15.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 11.5ms\n",
            "Speed: 3.9ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Fan, 1 Monitor, 12.1ms\n",
            "Speed: 2.4ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Monitor, 11.2ms\n",
            "Speed: 2.3ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Monitor, 11.2ms\n",
            "Speed: 2.7ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Monitor, 11.9ms\n",
            "Speed: 2.6ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 1 Monitor, 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 14.0ms\n",
            "Speed: 2.6ms preprocess, 14.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Keyboards, 1 Mouse, 11.5ms\n",
            "Speed: 2.5ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Keyboards, 1 Mouse, 11.5ms\n",
            "Speed: 2.4ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 12.2ms\n",
            "Speed: 2.5ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 3 Keyboards, 1 Mouse, 11.2ms\n",
            "Speed: 2.5ms preprocess, 11.2ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 19.8ms\n",
            "Speed: 2.4ms preprocess, 19.8ms inference, 8.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 19.1ms\n",
            "Speed: 4.4ms preprocess, 19.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 18.1ms\n",
            "Speed: 3.1ms preprocess, 18.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 13.1ms\n",
            "Speed: 3.8ms preprocess, 13.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 26.6ms\n",
            "Speed: 2.3ms preprocess, 26.6ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 1 Keyboard, 1 Mouse, 22.4ms\n",
            "Speed: 2.6ms preprocess, 22.4ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 21.1ms\n",
            "Speed: 2.6ms preprocess, 21.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 12.2ms\n",
            "Speed: 2.4ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 16.3ms\n",
            "Speed: 2.4ms preprocess, 16.3ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 11.1ms\n",
            "Speed: 2.4ms preprocess, 11.1ms inference, 6.3ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 13.2ms\n",
            "Speed: 2.6ms preprocess, 13.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 11.3ms\n",
            "Speed: 2.5ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 15.1ms\n",
            "Speed: 3.9ms preprocess, 15.1ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 19.7ms\n",
            "Speed: 2.4ms preprocess, 19.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 16.9ms\n",
            "Speed: 2.5ms preprocess, 16.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 15.8ms\n",
            "Speed: 2.5ms preprocess, 15.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 23.1ms\n",
            "Speed: 4.0ms preprocess, 23.1ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "\n",
            "0: 640x384 2 Keyboards, 1 Mouse, 17.3ms\n",
            "Speed: 6.3ms preprocess, 17.3ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the video and play it on your local device."
      ],
      "metadata": {
        "id": "m91WK8qp2dDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('processed_obj_test_vid.mp4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mNMwVXP__9Nt",
        "outputId": "383a7e31-68dd-450a-8880-57024c82afa3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ecab61a2-2f54-4d52-9d3f-8cc386e1e703\", \"processed_obj_test_vid.mp4\", 39618628)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "97j5-uzLATLj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}